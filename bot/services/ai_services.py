"""
AI æœåŠ¡æ¨¡å—
å°è£…å¯¹ OpenAI ç­‰ AI API çš„è°ƒç”¨
"""

import os
import re
from typing import Any, Dict, List, Optional

import openai
from loguru import logger
from md2tgmd import escape

from config.settings import config_manager


class AIServices:
    """AI æœåŠ¡ç®¡ç†å™¨"""

    def __init__(self):
        self.openai_client = None
        self.active_config_cache = None
        self._setup_openai()

    def _setup_openai(self):
        """è®¾ç½® OpenAI å®¢æˆ·ç«¯"""
        try:
            active_config = config_manager.get_active_openai_config()

            # æ£€æŸ¥é…ç½®æ˜¯å¦æœ‰å˜åŒ–ï¼Œå¦‚æœæ²¡æœ‰å˜åŒ–ä¸”å®¢æˆ·ç«¯å·²å­˜åœ¨ï¼Œåˆ™ç›´æ¥è¿”å›
            if (
                self.openai_client is not None
                and self.active_config_cache is not None
                and self.active_config_cache == active_config
            ):
                return

            if not active_config:
                logger.error("æ²¡æœ‰æ‰¾åˆ°æ´»åŠ¨çš„ OpenAI é…ç½®")
                self.openai_client = None
                self.active_config_cache = None
                return

            api_key = active_config.get("api_key")
            base_url = active_config.get("api_base_url", "https://api.openai.com/v1")

            if not api_key:
                logger.error("æ´»åŠ¨çš„ OpenAI é…ç½®ä¸­ç¼ºå°‘ API Key")
                self.openai_client = None
                self.active_config_cache = None
                return

            self.openai_client = openai.AsyncOpenAI(api_key=api_key, base_url=base_url)
            self.active_config_cache = active_config
            logger.info(
                f"OpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–æˆ–æ›´æ–°æˆåŠŸï¼Œä½¿ç”¨é…ç½®: {active_config.get('name', 'æœªå‘½å')}ï¼Œbase_url: {base_url}"
            )
        except Exception as e:
            logger.error(f"OpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.openai_client = None
            self.active_config_cache = None

    def reload_config(self):
        """é‡æ–°åŠ è½½é…ç½®å¹¶é‡æ–°åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        try:
            logger.info("é‡æ–°åŠ è½½AIæœåŠ¡é…ç½®...")
            self._setup_openai()
            logger.info("AIæœåŠ¡é…ç½®é‡æ–°åŠ è½½å®Œæˆ")
        except Exception as e:
            logger.error(f"é‡æ–°åŠ è½½AIæœåŠ¡é…ç½®å¤±è´¥: {e}")

    async def get_available_models(self) -> List[str]:
        """
        è·å–å½“å‰é…ç½®å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨

        Returns:
            æ¨¡å‹IDåˆ—è¡¨ï¼Œå¤±è´¥æ—¶è¿”å›ç©ºåˆ—è¡¨
        """
        try:
            self._setup_openai()
            if not self.openai_client:
                logger.error("OpenAI å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•è·å–æ¨¡å‹åˆ—è¡¨")
                return []

            # è°ƒç”¨ OpenAI API è·å–æ¨¡å‹åˆ—è¡¨
            models_response = await self.openai_client.models.list()

            # æå–æ¨¡å‹IDåˆ—è¡¨
            model_ids = [model.id for model in models_response.data]

            logger.info(f"æˆåŠŸè·å–åˆ° {len(model_ids)} ä¸ªå¯ç”¨æ¨¡å‹")
            return model_ids

        except openai.AuthenticationError:
            logger.error("OpenAI API è®¤è¯å¤±è´¥ï¼Œæ— æ³•è·å–æ¨¡å‹åˆ—è¡¨")
            return []
        except openai.RateLimitError:
            logger.warning("OpenAI API é€Ÿç‡é™åˆ¶ï¼Œæ— æ³•è·å–æ¨¡å‹åˆ—è¡¨")
            return []
        except Exception as e:
            logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
            return []

    async def chat_completion(
        self, history: List[Dict[str, Any]], user_id: Optional[int] = None
    ) -> Optional[str]:
        """
        AI å¯¹è¯å®Œæˆ

        Args:
            history: å¯¹è¯å†å²åˆ—è¡¨ï¼Œæ ¼å¼ [{"role": "user", "content": "æ¶ˆæ¯å†…å®¹"}]
            user_id: ç”¨æˆ·IDï¼Œç”¨äºæ—¥å¿—è®°å½•

        Returns:
            AI å›å¤å†…å®¹ï¼Œå¤±è´¥æ—¶è¿”å› None
        """
        try:
            self._setup_openai()
            if not self.openai_client:
                return "æŠ±æ­‰ï¼ŒAI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚"

            # è·å–é…ç½®
            openai_config = config_manager.get_active_openai_config()
            if not openai_config:
                return "æŠ±æ­‰ï¼ŒAI æœåŠ¡é…ç½®ä¸æ­£ç¡®ã€‚"

            model = openai_config.get("model", "gpt-3.5-turbo")
            max_tokens = openai_config.get("max_tokens", 1000)
            if not isinstance(max_tokens, int) or max_tokens <= 0:
                max_tokens = 1000
            temperature = openai_config.get("temperature")
            if temperature is None:
                temperature = 0.7

            # æ·»åŠ ç³»ç»Ÿæç¤ºåˆ°å†å²è®°å½•çš„æœ€å‰é¢
            system_prompt = config_manager.get(
                "features.chat.system_prompt",
                "ä½ æ˜¯ä¸€ä¸ªå‹å–„ã€æœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚è¯·ç”¨ç®€æ´æ˜äº†çš„ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚",
            )

            full_messages = [{"role": "system", "content": system_prompt}] + history

            # è°ƒç”¨ OpenAI API
            response = await self.openai_client.chat.completions.create(
                model=model,
                messages=full_messages,  # type: ignore
                max_tokens=max_tokens,
                temperature=temperature,
            )

            content = response.choices[0].message.content
            reply = content.strip() if content is not None else ""

            # è½¬æ¢ä¸º Telegram MarkdownV2 å®‰å…¨æ ¼å¼
            safe_reply = escape(reply)

            logger.info(
                f"AI å¯¹è¯å®Œæˆ - ç”¨æˆ·: {user_id}, æ¨¡å‹: {model}, å›å¤é•¿åº¦: {len(reply)}, è½¬æ¢åé•¿åº¦: {len(safe_reply)}"
            )
            logger.info(f"åŸå§‹å›å¤: {reply}")
            logger.info(f"è½¬æ¢åå›å¤: {safe_reply}")
            return safe_reply

        except openai.RateLimitError:
            logger.warning(f"OpenAI API é€Ÿç‡é™åˆ¶ - ç”¨æˆ·: {user_id}")
            return "æŠ±æ­‰ï¼Œå½“å‰è¯·æ±‚è¿‡å¤šï¼Œè¯·ç¨åå†è¯•ã€‚"
        except openai.AuthenticationError:
            logger.error("OpenAI API è®¤è¯å¤±è´¥")
            self._setup_openai()
            return "æŠ±æ­‰ï¼ŒAI æœåŠ¡é…ç½®æœ‰è¯¯ã€‚"
        except Exception as e:
            logger.error(f"AI å¯¹è¯å¤±è´¥ - ç”¨æˆ·: {user_id}, é”™è¯¯: {e}")
            return "æŠ±æ­‰ï¼ŒAI æœåŠ¡æš‚æ—¶å‡ºç°é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"

    async def generate_image(
        self, prompt: str, user_id: Optional[int] = None
    ) -> Optional[str]:
        """
        AI å›¾ç‰‡ç”Ÿæˆ

        Args:
            prompt: å›¾ç‰‡æè¿°
            user_id: ç”¨æˆ·IDï¼Œç”¨äºæ—¥å¿—è®°å½•

        Returns:
            å›¾ç‰‡URLï¼Œå¤±è´¥æ—¶è¿”å› None
        """
        try:
            self._setup_openai()
            if not self.openai_client:
                return None

            # è·å–é…ç½®
            ai_config = config_manager.get_ai_config()
            drawing_config = ai_config.get("drawing", {})

            model = drawing_config.get("model", "dall-e-3")
            size = drawing_config.get("size", "1024x1024")
            quality = drawing_config.get("quality", "standard")

            # è°ƒç”¨ OpenAI DALL-E API
            response = await self.openai_client.images.generate(
                model=model, prompt=prompt, size=size, quality=quality, n=1
            )

            image_url = response.data[0].url

            logger.info(
                f"AI å›¾ç‰‡ç”ŸæˆæˆåŠŸ - ç”¨æˆ·: {user_id}, æ¨¡å‹: {model}, æç¤º: {prompt[:50]}..."
            )
            return image_url

        except openai.RateLimitError:
            logger.warning(f"OpenAI API é€Ÿç‡é™åˆ¶ - ç”¨æˆ·: {user_id}")
            return None
        except openai.AuthenticationError:
            logger.error("OpenAI API è®¤è¯å¤±è´¥")
            self._setup_openai()
            return None
        except Exception as e:
            logger.error(f"AI å›¾ç‰‡ç”Ÿæˆå¤±è´¥ - ç”¨æˆ·: {user_id}, é”™è¯¯: {e}")
            return None

    async def search_web(
        self, query: str, user_id: Optional[int] = None
    ) -> Optional[str]:
        """
        è”ç½‘æœç´¢åŠŸèƒ½

        Args:
            query: æœç´¢æŸ¥è¯¢
            user_id: ç”¨æˆ·IDï¼Œç”¨äºæ—¥å¿—è®°å½•

        Returns:
            æœç´¢ç»“æœæ‘˜è¦ï¼Œå¤±è´¥æ—¶è¿”å› None
        """
        try:
            # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€å•çš„æœç´¢å®ç°
            # åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œä½ å¯èƒ½æƒ³è¦é›†æˆ Google Search API, Bing API ç­‰

            # ä½¿ç”¨ AI æ¥æ¨¡æ‹Ÿæœç´¢ç»“æœï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼‰
            search_prompt = f"""
            ç”¨æˆ·æœç´¢æŸ¥è¯¢: "{query}"
            
            è¯·åŸºäºä½ çš„çŸ¥è¯†åº“æä¾›ç›¸å…³ä¿¡æ¯ã€‚å¦‚æœè¿™æ˜¯ä¸€ä¸ªéœ€è¦å®æ—¶ä¿¡æ¯çš„æŸ¥è¯¢ï¼ˆå¦‚å¤©æ°”ã€æ–°é—»ã€è‚¡ä»·ç­‰ï¼‰ï¼Œ
            è¯·è¯´æ˜ä½ æ— æ³•æä¾›å®æ—¶ä¿¡æ¯ï¼Œå¹¶å»ºè®®ç”¨æˆ·æŸ¥çœ‹ç›¸å…³å®˜æ–¹ç½‘ç«™ã€‚
            
            è¯·ç”¨ç®€æ´æ˜äº†çš„ä¸­æ–‡å›ç­”ï¼ŒåŒ…å«æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚
            """

            messages = [{"role": "user", "content": search_prompt}]
            result = await self.chat_completion(messages, user_id)

            if result:
                logger.info(f"æœç´¢å®Œæˆ - ç”¨æˆ·: {user_id}, æŸ¥è¯¢: {query}")
                search_result = f"ğŸ” **æœç´¢ç»“æœï¼š{query}**\n\n{result}\n\nğŸ’¡ *æ³¨æ„ï¼šä»¥ä¸Šä¿¡æ¯åŸºäºAIçŸ¥è¯†åº“ï¼Œå¦‚éœ€æœ€æ–°ä¿¡æ¯è¯·æŸ¥çœ‹å®˜æ–¹æ¥æºã€‚*"
                return search_result

            return None

        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥ - ç”¨æˆ·: {user_id}, æŸ¥è¯¢: {query}, é”™è¯¯: {e}")
            return None

    async def summarize_messages(
        self, messages: List[str], chat_title: str = "ç¾¤èŠ"
    ) -> Optional[str]:
        """
        æ€»ç»“ç¾¤èŠæ¶ˆæ¯

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            chat_title: ç¾¤èŠæ ‡é¢˜

        Returns:
            æ€»ç»“å†…å®¹ï¼Œå¤±è´¥æ—¶è¿”å› None
        """
        try:
            if not messages:
                return None

            # è·å–æ€»ç»“æç¤ºè¯
            summary_prompt = config_manager.get(
                "features.auto_summary.summary_prompt",
                "è¯·æ€»ç»“ä»¥ä¸‹ç¾¤èŠå¯¹è¯çš„ä¸»è¦å†…å®¹å’Œè¯é¢˜ï¼š",
            )

            # æ„å»ºæ€»ç»“è¯·æ±‚
            messages_text = "\n".join(messages)

            full_prompt = f"""
            {summary_prompt}
            
            ç¾¤èŠåç§°: {chat_title}
            æ¶ˆæ¯æ•°é‡: {len(messages)}
            
            æ¶ˆæ¯å†…å®¹:
            {messages_text}
            
            è¯·æä¾›ä¸€ä¸ªç®€æ´çš„æ€»ç»“ï¼ŒåŒ…æ‹¬ï¼š
            1. ä¸»è¦è®¨è®ºè¯é¢˜
            2. é‡è¦ä¿¡æ¯æˆ–å†³å®š
            3. æ´»è·ƒå‚ä¸è€…
            4. å…¶ä»–å€¼å¾—æ³¨æ„çš„å†…å®¹
            
            è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒç®€æ´æ˜äº†ã€‚
            """

            chat_messages = [{"role": "user", "content": full_prompt}]
            summary = await self.chat_completion(chat_messages)

            if summary:
                logger.info(
                    f"ç¾¤èŠæ€»ç»“å®Œæˆ - ç¾¤èŠ: {chat_title}, æ¶ˆæ¯æ•°: {len(messages)}"
                )
                return summary

            return None

        except Exception as e:
            logger.error(f"ç¾¤èŠæ€»ç»“å¤±è´¥ - ç¾¤èŠ: {chat_title}, é”™è¯¯: {e}")
            return None


# å…¨å±€ AI æœåŠ¡å®ä¾‹
ai_services = AIServices()


async def get_rag_answer(question: str) -> str:
    """
    ä½¿ç”¨ RAG æ¨¡å‹æ£€ç´¢ç­”æ¡ˆã€‚
    æ­¤å®ç°ä¼šè¯»å– 'docs' ç›®å½•ä¸­çš„æ‰€æœ‰ markdown æ–‡æ¡£ï¼Œ
    å°†å…¶ä¸ç”¨æˆ·çš„é—®é¢˜ç»“åˆï¼Œç„¶åå‘é€ç»™ AI æ¨¡å‹ã€‚
    """
    logger.info(f"RAG æœåŠ¡è¢«è°ƒç”¨ï¼Œé—®é¢˜: {question}")
    try:
        # 1. è¯»å–æ‰€æœ‰ docs ä¸‹çš„ markdown æ–‡ä»¶
        docs_path = "docs"
        all_doc_content = []
        if os.path.exists(docs_path) and os.path.isdir(docs_path):
            for filename in os.listdir(docs_path):
                if filename.endswith(".md"):
                    filepath = os.path.join(docs_path, filename)
                    try:
                        with open(filepath, "r", encoding="utf-8") as f:
                            all_doc_content.append(f.read())
                    except Exception as e:
                        logger.warning(f"æ— æ³•è¯»å–æ–‡ä»¶ {filepath}: {e}")

        if not all_doc_content:
            logger.warning("RAG: åœ¨ docs ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ–‡æ¡£ã€‚")
            return "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯ä»¥å‚è€ƒçš„èƒŒæ™¯çŸ¥è¯†æ¥å›ç­”ä½ çš„é—®é¢˜ã€‚"

        doc_text = "\n\n---\n\n".join(all_doc_content)

        # 2. æ„å»º prompt
        # ç§»é™¤ doc_text ä¸­æ‰€æœ‰çš„ markdown å›¾ç‰‡é“¾æ¥ ![alt](url)
        doc_text_no_images = re.sub(r"!\[.*?\]\(.*?\)", "", doc_text)

        rag_prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½é—®ç­”æœºå™¨äººã€‚è¯·æ ¹æ®æˆ‘æä¾›çš„èƒŒæ™¯çŸ¥è¯†æ¥å›ç­”é—®é¢˜ã€‚
        å¦‚æœèƒŒæ™¯çŸ¥è¯†ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·ä½ æ— æ³•æ ¹æ®å·²çŸ¥ä¿¡æ¯å›ç­”ã€‚
        è¯·ä¸è¦ç¼–é€ èƒŒæ™¯çŸ¥è¯†ä¸­ä¸å­˜åœ¨çš„å†…å®¹ã€‚

        [èƒŒæ™¯çŸ¥è¯†]
        {doc_text_no_images}
        [/èƒŒæ™¯çŸ¥è¯†]

        ç°åœ¨ï¼Œè¯·æ ¹æ®ä»¥ä¸ŠèƒŒæ™¯çŸ¥è¯†å›ç­”æˆ‘çš„é—®é¢˜ã€‚

        [é—®é¢˜]
        {question}
        [/é—®é¢˜]
        """

        # 3. è°ƒç”¨å¤§æ¨¡å‹
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç›´æ¥è°ƒç”¨äº†å…¨å±€å®ä¾‹çš„ chat_completion æ–¹æ³•
        messages = [{"role": "user", "content": rag_prompt}]
        answer = await ai_services.chat_completion(messages)

        if not answer:
            return "æŠ±æ­‰ï¼ŒAI æœåŠ¡åœ¨å¤„ç†æ‚¨çš„é—®é¢˜æ—¶é‡åˆ°äº†éº»çƒ¦ã€‚"

        logger.info(f"RAG æœåŠ¡æˆåŠŸå›ç­”é—®é¢˜: {question}")
        return answer

    except Exception as e:
        logger.error(f"RAG æœåŠ¡å¤±è´¥ï¼Œé—®é¢˜ '{question}': {e}")
        return "æŠ±æ­‰ï¼ŒçŸ¥è¯†åº“é—®ç­”æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚"
